{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d52fcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fd5f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake=pd.read_csv(\"/kaggle/input/fake-and-real-news-dataset/Fake.csv\")\n",
    "true=pd.read_csv(\"/kaggle/input/fake-and-real-news-dataset/True.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5992c271",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking how the data looks like\n",
    "fake.head(10)\n",
    "fake.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc4005b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking different subjecys and their counts\n",
    "fake[\"subject\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf4204b",
   "metadata": {},
   "outputs": [],
   "source": [
    "true.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125e0439",
   "metadata": {},
   "outputs": [],
   "source": [
    "true.subject.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42462d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a categories for whether fake or true\n",
    "fake[\"category\"]=1\n",
    "true[\"category\"]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1b14d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a494dd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#joining the data the two data frame and reseting index\n",
    "df=pd.concat([fake ,true]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd530636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to check the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fea26fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "\n",
    "\n",
    "\n",
    "graph = sns.countplot(x=\"category\", data=df)\n",
    "plt.title(\"Count of Fake and True News\")\n",
    "\n",
    "#removing boundary\n",
    "graph.spines[\"right\"].set_visible(False)\n",
    "graph.spines[\"top\"].set_visible(False)\n",
    "graph.spines[\"left\"].set_visible(False)\n",
    "\n",
    "#annoting bars with the counts  \n",
    "for p in graph.patches:\n",
    "        height = p.get_height()\n",
    "        graph.text(p.get_x()+p.get_width()/2., height + 0.2,height ,ha=\"center\",fontsize=12)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00598872",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a count plot for subject column\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "\n",
    "\n",
    "\n",
    "graph = sns.countplot(x=\"subject\", data=df)\n",
    "plt.title(\"Count of Subjecs\")\n",
    "\n",
    "#removing boundary\n",
    "graph.spines[\"right\"].set_visible(False)\n",
    "graph.spines[\"top\"].set_visible(False)\n",
    "graph.spines[\"left\"].set_visible(False)\n",
    "\n",
    "#annoting bars with the counts  \n",
    "for p in graph.patches:\n",
    "        height = p.get_height()\n",
    "        graph.text(p.get_x()+p.get_width()/2., height + 0.2,height ,ha=\"center\",fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269d36c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the missing values in each columns\n",
    "df.isna().sum()*100/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f4c60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65440b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if there is empty string in TEXT column\n",
    "blanks = []\n",
    "\n",
    "# index and text of the document\n",
    "for index, text in df[\"text\"].items():  \n",
    "    if text.isspace():  # if the string is only whitespace\n",
    "        blanks.append(index)  # note the index\n",
    "\n",
    "len(blanks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0f6fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "blanks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb2685c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instead of dropping these values we are going to merge title with text\n",
    "\n",
    "df[\"text\"] =df[\"title\"]+df[\"text\"]\n",
    "\n",
    "#we only need two columns rest can be ignored\n",
    "\n",
    "df=df[[\"text\",\"category\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6325bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#importing libraries for cleaning puprose\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "import spacy\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbffc634",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading spacy library\n",
    "nlp=spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "#creating instance\n",
    "lemma=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfd4f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating list of stopwords containing stopwords from spacy and nltk\n",
    "\n",
    "#stopwords of spacy\n",
    "list1=nlp.Defaults.stop_words\n",
    "print(len(list1))\n",
    "\n",
    "#stopwords of NLTK\n",
    "list2=stopwords.words('english')\n",
    "print(len(list2))\n",
    "\n",
    "#combining the stopword list\n",
    "Stopwords=set((set(list1)|set(list2)))\n",
    "print(len(Stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749c9491",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Initialize stopwords and lemmatizer\n",
    "Stopwords = set(stopwords.words('english'))\n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Cleans input text by:\n",
    "    - Converting to lowercase\n",
    "    - Expanding contractions\n",
    "    - Removing special characters\n",
    "    - Removing stopwords\n",
    "    - Lemmatizing words\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "\n",
    "    # Expanding common contractions\n",
    "    text = re.sub(r\"i'm\", \"i am\", text)\n",
    "    text = re.sub(r\"he's\", \"he is\", text)\n",
    "    text = re.sub(r\"she's\", \"she is\", text)\n",
    "    text = re.sub(r\"it's\", \"it is\", text)\n",
    "    text = re.sub(r\"that's\", \"that is\", text)\n",
    "    text = re.sub(r\"what's\", \"what is\", text)\n",
    "    text = re.sub(r\"where's\", \"where is\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"won't\", \"will not\", text)\n",
    "    text = re.sub(r\"can't\", \"cannot\", text)\n",
    "\n",
    "    # Removing special characters and extra whitespace\n",
    "    text = re.sub(r\"[^a-z0-9\\s]\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "    # Lemmatization and stopword removal\n",
    "    cleaned = []\n",
    "    for word in text.split():\n",
    "        if word not in Stopwords:\n",
    "            cleaned.append(lemma.lemmatize(word))\n",
    "\n",
    "    return \" \".join(cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81520dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_text'] = df['text'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522d150c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cfc375",
   "metadata": {},
   "outputs": [],
   "source": [
    "#True News\n",
    "plt.figure(figsize = (20,20))\n",
    "Wc = WordCloud(max_words = 500 , width = 1600 , height = 800).generate(\" \".join(df[df.category == 0].text))\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(Wc , interpolation = 'bilinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47416143",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating more intiuive wordcloud \n",
    "\n",
    "#pil is pillow and used for image manupulation\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a62696",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a mask of thumb\n",
    "thumb=\"../input/images-coud/thumbs-up.png\"\n",
    "icon=Image.open(thumb)\n",
    "mask=Image.new(mode=\"RGB\",size=icon.size, color=(255,255,255))\n",
    "mask.paste(icon, box=icon)\n",
    "\n",
    "rgb_array=np.array(mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818e4aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#True News\n",
    "plt.figure(figsize = (10,10))\n",
    "Wc = WordCloud(mask=rgb_array,max_words = 2000 , width = 1600 ,\n",
    "               height = 800)\n",
    "\n",
    "Wc.generate(\" \".join(df[df.category == 0].text))\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(Wc , interpolation = 'bilinear')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96510fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating word cloud using skull image for fake news which depict that \n",
    "#fake news are dangerous \n",
    "\n",
    "skull=\"../input/images-coud/skull-icon.png\"\n",
    "icon=Image.open(skull)\n",
    "mask=Image.new(mode=\"RGB\",size=icon.size, color=(255,255,255))\n",
    "mask.paste(icon, box=icon)\n",
    "\n",
    "rgb_array=np.array(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0aae0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fake News\n",
    "plt.figure(figsize = (15,15))\n",
    "Wc = WordCloud(mask=rgb_array,max_words = 2000 , width = 1600 ,\n",
    "               height = 800)\n",
    "\n",
    "Wc.generate(\" \".join(df[df.category == 1].text))\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(Wc , interpolation = 'bilinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93697d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X=df[\"text\"] #feature \n",
    "y=df[\"category\"] # traget\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee47e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries to build a pipline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9c61df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this pipe line will take the text and vectorise it , and then TF-IDF, then fitting the model\n",
    "\n",
    "text_clf=Pipeline([(\"tfidf\",TfidfVectorizer()),(\"clf\",LinearSVC())])\n",
    "text_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c8b970",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making prediction using the model\n",
    "predictions=text_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e8bc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d694cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#overall acuracy\n",
    "print(metrics.accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eaa6f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix\n",
    "print(metrics.confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cced0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07db2610",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d1f0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e199646b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, set_seed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ff784b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained GPT-2 model for text generation\n",
    "generator = pipeline(\"text-generation\", model=\"gpt2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768bd0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fake_news(prompt, max_length=100):\n",
    "    set_seed(42)  # ensures reproducible results\n",
    "    result = generator(prompt, max_length=max_length, num_return_sequences=1)\n",
    "    return result[0]['generated_text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7004fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Breaking News: Scientists discover a portal to\"\n",
    "generated_news = generate_fake_news(prompt, max_length=120)\n",
    "\n",
    "print(\"📰 Generated Fake News:\\n\")\n",
    "print(generated_news)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b388565",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = input(\"Enter a prompt for fake news: \")\n",
    "print(generate_fake_news(prompt, max_length=100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e9a287",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"generated_fake_news.txt\", \"w\") as f:\n",
    "    f.write(generated_news)\n",
    "\n",
    "print(\"✅ Article saved to 'generated_fake_news.txt'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e80bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 🔁 Combined: Generate Fake News and Detect it\n",
    "prompt = \"Breaking News: A mysterious signal was received from Mars.\"\n",
    "\n",
    "# Generate fake article\n",
    "generated_article = generate_fake_news(prompt, max_length=120)\n",
    "print(\"📰 Generated Article:\")\n",
    "print(generated_article)\n",
    "\n",
    "# Detect using the trained model\n",
    "label, confidence = detect_news(generated_article)\n",
    "print(\"\\n🔍 Detector Prediction:\")\n",
    "print(f\"→ This article is: {label} ({confidence}% confidence)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}